# Anubis

## DescriÃ§Ã£o

O Anubis Ã© um microserviÃ§o responsÃ¡vel pela orquestraÃ§Ã£o do envio de dados de alunos pagantes para APIs de instituiÃ§Ãµes de ensino superior, como Kroton e EstÃ¡cio. Ele gerencia o fluxo de inscriÃ§Ãµes vindas do Quero Bolsa e dos novos marketplaces (Ead.com, Guia da Carreira e Mundo Vestibular), organizando os payloads e registrando logs estruturados com o status das tentativas, alÃ©m de implementar mecanismos automÃ¡ticos de retry para falhas temporÃ¡rias.

O escopo do serviÃ§o nÃ£o inclui o envio de leads do Quero CaptaÃ§Ã£o, alunos pagantes de outros produtos da Qeevo, agendamento de envios ou interface para reenvio manual de falhas. O foco estÃ¡ na integraÃ§Ã£o eficiente e segura dos dados de alunos pagantes entre os sistemas internos e as APIs das instituiÃ§Ãµes parceiras.


## Modelo de Dados (ER Diagram)

<details>
<summary>ğŸ“Š Visualizar Diagrama Entidade-Relacionamento</summary>

```mermaid
%%{init: {
  'theme':'base',
  'themeVariables': {
    'primaryColor':'#E8F4FD',
    'primaryBorderColor':'#4A90E2',
    'primaryTextColor':'#2C3E50',
    'secondaryColor':'#F0F8E8',
    'tertiaryColor':'#FDF2E8',
    'quaternaryColor':'#F8E8F8',
    'lineColor':'#5D6D7E',
    'fontFamily':'Inter,Segoe UI,Arial'
  }
}}%%
erDiagram
  SUBSCRIPTIONS }o--|| INTEGRATIONS : "belongs_to integration"
  INTEGRATIONS ||--o{ SUBSCRIPTIONS : "has_many subscriptions"
  
  SUBSCRIPTIONS }o--|| INTEGRATION_FILTERS : "belongs_to integration_filter"
  INTEGRATION_FILTERS ||--o{ SUBSCRIPTIONS : "has_many subscriptions"
  
  INTEGRATIONS ||--o{ INTEGRATION_FILTERS : "has_many integration_filters"
  INTEGRATION_FILTERS }o--|| INTEGRATIONS : "belongs_to integration"
  
  INTEGRATIONS ||--o{ INTEGRATION_TOKENS : "has_many integration_tokens"
  INTEGRATION_TOKENS }o--|| INTEGRATIONS : "belongs_to integration"
  
  SUBSCRIPTIONS ||--o{ SUBSCRIPTION_EVENTS : "has_many subscription_events"
  SUBSCRIPTION_EVENTS }o--|| SUBSCRIPTIONS : "belongs_to subscription"

  INTEGRATIONS {
    integer id PK
    string name "ğŸ“‹ Integration Name"
    string type "ğŸ”§ Integration Type"
    string key "ğŸ”‘ API Key"
    integer interval "â±ï¸ Sync Interval (minutes)"
    timestamp created_at
    timestamp updated_at
  }
  
  INTEGRATION_FILTERS {
    integer id PK
    integer integration_id FK "ğŸ”— Integration Reference"
    json filter "ğŸ¯ Filter Configuration"
    string type "ğŸ“ Filter Type"
    boolean enabled "âœ… Is Active"
    timestamp created_at
    timestamp updated_at
  }
  
  SUBSCRIPTIONS {
    integer id PK
    integer integration_id FK "ğŸ”Œ Integration Reference"
    integer integration_filter_id FK "ğŸ¯ Filter Reference"
    integer order_id "ğŸ“¦ Order ID"
    string origin "ğŸŒ Data Source"
    string cpf "ğŸ‘¤ Student CPF"
    json payload "ğŸ“„ Student Data"
    string status "ğŸ“Š Processing Status"
    timestamp sent_at "ğŸ“¤ Sent Timestamp"
    timestamp checked_at "ğŸ‘€ Last Check"
    timestamp scheduled_to "â° Scheduled For"
    timestamp created_at
    timestamp updated_at
  }
  
  INTEGRATION_TOKENS {
    integer id PK
    integer integration_id FK "ğŸ”— Integration Reference"
    string key "ğŸ” Token Key"
    string value "ğŸ« Token Value"
    timestamp valid_until "â³ Expiration Date"
    timestamp created_at
    timestamp updated_at
  }
  
  SUBSCRIPTION_EVENTS {
    integer id PK
    integer subscription_id FK "ğŸ“¦ Subscription Reference"
    string status "ğŸ“ˆ Event Status"
    string operation_name "âš™ï¸ Operation Type"
    string error_message "âŒ Error Details"
    json request "ğŸ“¤ Request Payload"
    json response "ğŸ“¥ Response Data"
    string model "ğŸ·ï¸ Model Name"
    timestamp created_at
    timestamp updated_at
  }
```

</details>

### Comandos usados para Gerar os Models

```bash
rails g model Integration name:string type:string key:string interval:integer --no-test-framework
rails g model IntegrationFilter integration:references filter:json type:string enabled:boolean --no-test-framework
rails g model Subscription integration:references integration_filter:references order_id:integer origin:string cpf:string payload:json status:string sent_at:timestamp checked_at:timestamp scheduled_to:timestamp --no-test-framework
rails g model IntegrationToken integration:references key:string value:string valid_until:timestamp --no-test-framework
rails g model SubscriptionEvent subscription:references status:string operation_name:string error_message:string request:json response:json model:string --no-test-framework
```

## Fluxos do Projeto

### ğŸ—ï¸ VisÃ£o Geral do Sistema (Overview)

```mermaid
%%{init: {
  'theme':'base',
  'themeVariables': {
    'primaryColor':'#E8F4FD',
    'primaryBorderColor':'#4A90E2',
    'primaryTextColor':'#2C3E50',
    'secondaryColor':'#F0F8E8',
    'tertiaryColor':'#FDF2E8',
    'quaternaryColor':'#F8E8F8',
    'lineColor':'#5D6D7E',
    'fontFamily':'Inter,Segoe UI,Arial'
  }
}}%%
flowchart TD
    subgraph "ğŸŒ Marketplaces"
        QB["ğŸ“ Quero Bolsa"]
        EAD["ğŸ“š EAD.com"]
        GC["ğŸ—ï¸ Guia da Carreira"]
        MV["ğŸ¯ Mundo Vestibular"]
    end
    
    subgraph "âš™ï¸ Anubis Service"
        ANUBIS["ğŸ”„ Anubis<br/>Orchestrator"]
        QUEUE["ğŸ“¥ Message Queue"]
        PROC["âš¡ Processor"]
        LOG["ğŸ“ Event Logger"]
    end
    
    subgraph "ğŸ›ï¸ Institution APIs"
        KROTON["ğŸ¢ Kroton API"]
        ESTACIO["ğŸ« EstÃ¡cio API"]
        OTHER["ğŸ¤ Other APIs"]
    end
    
    subgraph "ğŸ’¾ Storage"
        DB["ğŸ—„ï¸ PostgreSQL"]
        KAFKA["ğŸ“¨ Kafka"]
    end
    
    QB --> ANUBIS
    EAD --> ANUBIS
    GC --> ANUBIS
    MV --> ANUBIS
    
    ANUBIS --> QUEUE
    QUEUE --> PROC
    PROC --> LOG
    
    PROC --> KROTON
    PROC --> ESTACIO
    PROC --> OTHER
    
    LOG --> DB
    ANUBIS --> KAFKA
    
    classDef marketplace fill:#E8F4FD,stroke:#4A90E2,color:#2C3E50
    classDef anubis fill:#F0F8E8,stroke:#7CB342,color:#2C3E50
    classDef institution fill:#FDF2E8,stroke:#FF9800,color:#2C3E50
    classDef storage fill:#F8E8F8,stroke:#9C27B0,color:#2C3E50
    
    class QB,EAD,GC,MV marketplace
    class ANUBIS,QUEUE,PROC,LOG anubis
    class KROTON,ESTACIO,OTHER institution
    class DB,KAFKA storage
```

**ğŸ“‹ ExplicaÃ§Ã£o da VisÃ£o Geral:**

O Anubis atua como um **orquestrador central** que recebe dados de alunos pagantes de mÃºltiplos marketplaces educacionais e os distribui para as APIs das instituiÃ§Ãµes de ensino superior. O fluxo Ã© unidirecional e assÃ­ncrono:

- **Entrada de Dados**: Quero Bolsa, EAD.com, Guia da Carreira e Mundo Vestibular enviam informaÃ§Ãµes de inscriÃ§Ãµes
- **Processamento**: O Anubis valida, transforma e enfileira os dados para processamento
- **DistribuiÃ§Ã£o**: Os dados sÃ£o enviados para APIs de instituiÃ§Ãµes como Kroton, EstÃ¡cio e outras
- **PersistÃªncia**: PostgreSQL armazena os dados estruturados e logs, enquanto Kafka gerencia mensagens assÃ­ncronas
- **Monitoramento**: Cada operaÃ§Ã£o Ã© logada para auditoria e debugging

### ğŸ”§ Arquitetura de ServiÃ§os

```mermaid
%%{init: {
  'theme':'base',
  'themeVariables': {
    'primaryColor':'#E8F4FD',
    'primaryBorderColor':'#4A90E2',
    'primaryTextColor':'#2C3E50',
    'secondaryColor':'#F0F8E8',
    'tertiaryColor':'#FDF2E8',
    'quaternaryColor':'#F8E8F8',
    'lineColor':'#5D6D7E',
    'fontFamily':'Inter,Segoe UI,Arial'
  }
}}%%
flowchart LR
    subgraph "ğŸ“Š Data Sources"
        ORDER["ğŸ“¦ Order Service"]
        STUDENT["ğŸ‘¤ Student Data"]
    end
    
    subgraph "ğŸ”„ Anubis Core"
        REGISTER["ğŸ“‹ Register Sync"]
        SCHEDULER["â° Scheduler"]
        CHECKER["ğŸ” Checker"]
        RETRY["ğŸ”„ Retry Logic"]
    end
    
    subgraph "ğŸ¯ Integration Layer"
        FILTER["ğŸ§° Filters"]
        TOKEN["ğŸ” Token Manager"]
        PAYLOAD["ğŸ“„ Payload Builder"]
    end
    
    subgraph "ğŸ“¤ Output Services"
        API_CLIENT["ğŸŒ API Client"]
        EVENT_LOG["ğŸ“ Event Logger"]
    end
    
    ORDER --> REGISTER
    STUDENT --> REGISTER
    
    REGISTER --> SCHEDULER
    SCHEDULER --> CHECKER
    CHECKER --> RETRY
    
    REGISTER --> FILTER
    FILTER --> TOKEN
    TOKEN --> PAYLOAD
    
    PAYLOAD --> API_CLIENT
    API_CLIENT --> EVENT_LOG
    CHECKER --> EVENT_LOG
    
    classDef source fill:#E8F4FD,stroke:#4A90E2,color:#2C3E50
    classDef core fill:#F0F8E8,stroke:#7CB342,color:#2C3E50
    classDef integration fill:#FDF2E8,stroke:#FF9800,color:#2C3E50
    classDef output fill:#F8E8F8,stroke:#9C27B0,color:#2C3E50
    
    class ORDER,STUDENT source
    class REGISTER,SCHEDULER,CHECKER,RETRY core
    class FILTER,TOKEN,PAYLOAD integration
    class API_CLIENT,EVENT_LOG output
```

**âš™ï¸ ExplicaÃ§Ã£o da Arquitetura de ServiÃ§os:**

Esta arquitetura modular divide o Anubis em **componentes especializados** que trabalham em conjunto:

- **Fontes de Dados**: Order Service e Student Data fornecem as informaÃ§Ãµes base dos alunos
- **NÃºcleo de Processamento**: 
  - **Register Sync**: Processa inscriÃ§Ãµes em tempo real
  - **Scheduler**: Agenda tarefas e verificaÃ§Ãµes periÃ³dicas
  - **Checker**: Monitora status das integraÃ§Ãµes
  - **Retry Logic**: Gerencia reenvios automÃ¡ticos em caso de falha
- **Camada de IntegraÃ§Ã£o**:
  - **Filters**: Aplicam regras de negÃ³cio especÃ­ficas por instituiÃ§Ã£o
  - **Token Manager**: Gerencia autenticaÃ§Ã£o e tokens de acesso
  - **Payload Builder**: ConstrÃ³i dados no formato esperado por cada API
- **ServiÃ§os de SaÃ­da**:
  - **API Client**: Comunica com APIs externas das instituiÃ§Ãµes
  - **Event Logger**: Registra todos os eventos para auditoria

#### ğŸ“‹ Fluxo Register Sync

```mermaid
%%{init: {
  'theme':'base',
  'themeVariables': {
    'primaryColor':'#E8F4FD',
    'primaryBorderColor':'#4A90E2',
    'primaryTextColor':'#2C3E50',
    'secondaryColor':'#F0F8E8',
    'tertiaryColor':'#FDF2E8',
    'quaternaryColor':'#F8E8F8',
    'lineColor':'#5D6D7E',
    'fontFamily':'Inter,Segoe UI,Arial'
  }
}}%%
flowchart TD
    START["ğŸš€ Start Process"]
    
    subgraph "ğŸ“¥ Data Collection"
        RECEIVE["ğŸ“¨ Receive Order Event"]
        VALIDATE["âœ… Validate Data"]
        EXTRACT["ğŸ” Extract Student Info"]
    end
    
    subgraph "ğŸ¯ Integration Matching"
        FIND_INT["ğŸ” Find Integrations"]
        APPLY_FILTER["ğŸ§° Apply Filters"]
        CHECK_RULES["ğŸ“‹ Check Rules"]
    end
    
    subgraph "ğŸ“„ Payload Processing"
        BUILD_PAYLOAD["ğŸ”§ Build Payload"]
        ADD_TOKEN["ğŸ” Add Auth Token"]
        VALIDATE_PAYLOAD["âœ… Validate Payload"]
    end
    
    subgraph "ğŸ“¤ Delivery"
        SEND_API["ğŸŒ Send to Institution API"]
        LOG_EVENT["ğŸ“ Log Event"]
        SCHEDULE_CHECK["â° Schedule Check"]
    end
    
    SUCCESS["âœ… Success"]
    ERROR["âŒ Error"]
    RETRY["ğŸ”„ Schedule Retry"]
    
    START --> RECEIVE
    RECEIVE --> VALIDATE
    VALIDATE --> EXTRACT
    
    EXTRACT --> FIND_INT
    FIND_INT --> APPLY_FILTER
    APPLY_FILTER --> CHECK_RULES
    
    CHECK_RULES --> BUILD_PAYLOAD
    BUILD_PAYLOAD --> ADD_TOKEN
    ADD_TOKEN --> VALIDATE_PAYLOAD
    
    VALIDATE_PAYLOAD --> SEND_API
    SEND_API --> LOG_EVENT
    LOG_EVENT --> SCHEDULE_CHECK
    
    SCHEDULE_CHECK --> SUCCESS
    
    VALIDATE -->|âŒ Invalid| ERROR
    CHECK_RULES -->|âŒ No Match| ERROR
    SEND_API -->|âŒ Failed| ERROR
    
    ERROR --> RETRY
    RETRY --> FIND_INT
    
    classDef start fill:#E8F4FD,stroke:#4A90E2,color:#2C3E50
    classDef process fill:#F0F8E8,stroke:#7CB342,color:#2C3E50
    classDef decision fill:#FDF2E8,stroke:#FF9800,color:#2C3E50
    classDef endNode fill:#F8E8F8,stroke:#9C27B0,color:#2C3E50
    
    class START start
    class RECEIVE,VALIDATE,EXTRACT,FIND_INT,APPLY_FILTER,CHECK_RULES,BUILD_PAYLOAD,ADD_TOKEN,VALIDATE_PAYLOAD,SEND_API,LOG_EVENT,SCHEDULE_CHECK process
    class SUCCESS,ERROR,RETRY endNode
```

**ğŸ”„ ExplicaÃ§Ã£o do Register Sync:**

O **Register Sync** Ã© o processo principal de sincronizaÃ§Ã£o em tempo real que processa cada inscriÃ§Ã£o individualmente:

1. **Coleta de Dados**:
   - Recebe eventos de inscriÃ§Ã£o dos marketplaces
   - Valida integridade e formato dos dados
   - Extrai informaÃ§Ãµes do aluno (CPF, dados pessoais, curso)

2. **Matching de IntegraÃ§Ã£o**:
   - Busca integraÃ§Ãµes ativas para a instituiÃ§Ã£o
   - Aplica filtros especÃ­ficos (curso, regiÃ£o, perfil do aluno)
   - Verifica regras de negÃ³cio antes do envio

3. **PreparaÃ§Ã£o do Payload**:
   - ConstrÃ³i payload no formato esperado pela API da instituiÃ§Ã£o
   - Adiciona tokens de autenticaÃ§Ã£o vÃ¡lidos
   - Valida estrutura final do payload

4. **Entrega e Logging**:
   - Envia dados para API da instituiÃ§Ã£o
   - Registra evento com status de sucesso/falha
   - Agenda verificaÃ§Ã£o posterior do status de processamento

5. **Tratamento de Erros**:
   - Em caso de falha, programa retry automÃ¡tico
   - MantÃ©m contador de tentativas
   - Escalona para intervenÃ§Ã£o manual apÃ³s limite de tentativas

#### â° Fluxo Register Cron

```mermaid
%%{init: {
  'theme':'base',
  'themeVariables': {
    'primaryColor':'#E8F4FD',
    'primaryBorderColor':'#4A90E2',
    'primaryTextColor':'#2C3E50',
    'secondaryColor':'#F0F8E8',
    'tertiaryColor':'#FDF2E8',
    'quaternaryColor':'#F8E8F8',
    'lineColor':'#5D6D7E',
    'fontFamily':'Inter,Segoe UI,Arial'
  }
}}%%
flowchart TD
    CRON_START["â° Cron Job Started"]
    
    subgraph "ğŸ” Discovery Phase"
        FETCH_INTEGRATIONS["ğŸ“‹ Fetch Active Integrations"]
        CHECK_INTERVAL["â±ï¸ Check Sync Intervals"]
        FILTER_DUE["ğŸ¯ Filter Due Syncs"]
    end
    
    subgraph "ğŸ“Š Data Processing"
        FETCH_ORDERS["ğŸ“¦ Fetch Pending Orders"]
        GROUP_BY_INT["ğŸ—‚ï¸ Group by Integration"]
        PREPARE_BATCH["ğŸ“‹ Prepare Batch"]
    end
    
    subgraph "âš¡ Batch Execution"
        PROCESS_BATCH["âš¡ Process Batch"]
        APPLY_FILTERS["ğŸ§° Apply Integration Filters"]
        BUILD_PAYLOADS["ğŸ“„ Build Payloads"]
    end
    
    subgraph "ğŸ“¤ Delivery & Logging"
        SEND_BATCH["ğŸŒ Send Batch to APIs"]
        LOG_RESULTS["ğŸ“ Log Results"]
        UPDATE_STATUS["ğŸ“Š Update Status"]
    end
    
    COMPLETE["âœ… Cron Complete"]
    ERROR_HANDLER["âŒ Error Handler"]
    SCHEDULE_RETRY["ğŸ”„ Schedule Retry"]
    
    CRON_START --> FETCH_INTEGRATIONS
    FETCH_INTEGRATIONS --> CHECK_INTERVAL
    CHECK_INTERVAL --> FILTER_DUE
    
    FILTER_DUE --> FETCH_ORDERS
    FETCH_ORDERS --> GROUP_BY_INT
    GROUP_BY_INT --> PREPARE_BATCH
    
    PREPARE_BATCH --> PROCESS_BATCH
    PROCESS_BATCH --> APPLY_FILTERS
    APPLY_FILTERS --> BUILD_PAYLOADS
    
    BUILD_PAYLOADS --> SEND_BATCH
    SEND_BATCH --> LOG_RESULTS
    LOG_RESULTS --> UPDATE_STATUS
    
    UPDATE_STATUS --> COMPLETE
    
    PROCESS_BATCH -->|âŒ Error| ERROR_HANDLER
    SEND_BATCH -->|âŒ Failed| ERROR_HANDLER
    ERROR_HANDLER --> SCHEDULE_RETRY
    SCHEDULE_RETRY --> PROCESS_BATCH
    
    classDef cron fill:#E8F4FD,stroke:#4A90E2,color:#2C3E50
    classDef discovery fill:#F0F8E8,stroke:#7CB342,color:#2C3E50
    classDef processing fill:#FDF2E8,stroke:#FF9800,color:#2C3E50
    classDef delivery fill:#F8E8F8,stroke:#9C27B0,color:#2C3E50
    classDef endNode fill:#FCE4EC,stroke:#E91E63,color:#2C3E50
    
    class CRON_START cron
    class FETCH_INTEGRATIONS,CHECK_INTERVAL,FILTER_DUE discovery
    class FETCH_ORDERS,GROUP_BY_INT,PREPARE_BATCH,PROCESS_BATCH,APPLY_FILTERS,BUILD_PAYLOADS processing
    class SEND_BATCH,LOG_RESULTS,UPDATE_STATUS delivery
    class COMPLETE,ERROR_HANDLER,SCHEDULE_RETRY endNode
```

**â° ExplicaÃ§Ã£o do Register Cron:**

O **Register Cron** Ã© o processo batch que executa periodicamente para processar volumes maiores de dados:

1. **Fase de Descoberta**:
   - Executa em intervalos programados (ex: a cada hora)
   - Busca todas as integraÃ§Ãµes ativas no sistema
   - Filtra integraÃ§Ãµes que estÃ£o no tempo de sincronizaÃ§Ã£o
   - Identifica quais precisam de processamento batch

2. **Processamento de Dados**:
   - Busca pedidos pendentes no perÃ­odo
   - Agrupa por integraÃ§Ã£o para otimizar processamento
   - Prepara lotes (batches) para envio em massa

3. **ExecuÃ§Ã£o em Lote**:
   - Processa mÃºltiplas inscriÃ§Ãµes simultaneamente
   - Aplica filtros de integraÃ§Ã£o em massa
   - ConstrÃ³i payloads otimizados para envio batch

4. **Entrega e Monitoramento**:
   - Envia lotes para APIs das instituiÃ§Ãµes
   - Registra resultados de cada lote processado
   - Atualiza status de todas as inscriÃ§Ãµes processadas

5. **RecuperaÃ§Ã£o de Erros**:
   - Identifica lotes que falharam
   - Agenda reprocessamento automÃ¡tico
   - MantÃ©m mÃ©tricas de performance e taxa de sucesso

**ğŸ’¡ DiferenÃ§a entre Sync e Cron:**
- **Sync**: Processa inscriÃ§Ãµes individuais em tempo real
- **Cron**: Processa lotes de inscriÃ§Ãµes em intervalos programados

#### ğŸ” Fluxo Checker

```mermaid
%%{init: {
  'theme':'base',
  'themeVariables': {
    'primaryColor':'#E8F4FD',
    'primaryBorderColor':'#4A90E2',
    'primaryTextColor':'#2C3E50',
    'secondaryColor':'#F0F8E8',
    'tertiaryColor':'#FDF2E8',
    'quaternaryColor':'#F8E8F8',
    'lineColor':'#5D6D7E',
    'fontFamily':'Inter,Segoe UI,Arial'
  }
}}%%
flowchart TD
    CHECKER_START["ğŸ” Checker Started"]
    
    subgraph "ğŸ“Š Status Monitoring"
        FETCH_PENDING["ğŸ“‹ Fetch Pending Subscriptions"]
        CHECK_SCHEDULE["â° Check Scheduled Time"]
        FILTER_READY["ğŸ¯ Filter Ready to Check"]
    end
    
    subgraph "ğŸŒ API Verification"
        CALL_STATUS_API["ğŸ“ Call Institution Status API"]
        PARSE_RESPONSE["ğŸ“„ Parse Response"]
        EXTRACT_STATUS["ğŸ” Extract Status"]
    end
    
    subgraph "ğŸ”„ Status Processing"
        COMPARE_STATUS["âš–ï¸ Compare with Current"]
        UPDATE_SUBSCRIPTION["ğŸ“Š Update Subscription"]
        DETERMINE_ACTION["ğŸ¤” Determine Next Action"]
    end
    
    subgraph "ğŸ“ Event Logging"
        LOG_CHECK["ğŸ“ Log Check Event"]
        UPDATE_TIMESTAMP["â° Update Check Timestamp"]
        STORE_RESPONSE["ğŸ’¾ Store API Response"]
    end
    
    subgraph "ğŸ¯ Action Decision"
        SUCCESS["âœ… Processing Complete"]
        PENDING["â³ Still Pending"]
        FAILED["âŒ Processing Failed"]
        RETRY_NEEDED["ğŸ”„ Retry Required"]
    end
    
    SCHEDULE_NEXT["â° Schedule Next Check"]
    TRIGGER_RETRY["ğŸ”„ Trigger Retry Process"]
    COMPLETE["âœ… Check Complete"]
    
    CHECKER_START --> FETCH_PENDING
    FETCH_PENDING --> CHECK_SCHEDULE
    CHECK_SCHEDULE --> FILTER_READY
    
    FILTER_READY --> CALL_STATUS_API
    CALL_STATUS_API --> PARSE_RESPONSE
    PARSE_RESPONSE --> EXTRACT_STATUS
    
    EXTRACT_STATUS --> COMPARE_STATUS
    COMPARE_STATUS --> UPDATE_SUBSCRIPTION
    UPDATE_SUBSCRIPTION --> DETERMINE_ACTION
    
    DETERMINE_ACTION --> LOG_CHECK
    LOG_CHECK --> UPDATE_TIMESTAMP
    UPDATE_TIMESTAMP --> STORE_RESPONSE
    
    STORE_RESPONSE --> SUCCESS
    STORE_RESPONSE --> PENDING
    STORE_RESPONSE --> FAILED
    STORE_RESPONSE --> RETRY_NEEDED
    
    SUCCESS --> COMPLETE
    PENDING --> SCHEDULE_NEXT
    FAILED --> COMPLETE
    RETRY_NEEDED --> TRIGGER_RETRY
    
    SCHEDULE_NEXT --> COMPLETE
    TRIGGER_RETRY --> COMPLETE
    
    CALL_STATUS_API -->|âŒ API Error| FAILED
    
    classDef start fill:#E8F4FD,stroke:#4A90E2,color:#2C3E50
    classDef monitoring fill:#F0F8E8,stroke:#7CB342,color:#2C3E50
    classDef api fill:#FDF2E8,stroke:#FF9800,color:#2C3E50
    classDef processing fill:#F8E8F8,stroke:#9C27B0,color:#2C3E50
    classDef decision fill:#FCE4EC,stroke:#E91E63,color:#2C3E50
    classDef endNode fill:#E1F5FE,stroke:#00BCD4,color:#2C3E50
    
    class CHECKER_START start
    class FETCH_PENDING,CHECK_SCHEDULE,FILTER_READY monitoring
    class CALL_STATUS_API,PARSE_RESPONSE,EXTRACT_STATUS api
    class COMPARE_STATUS,UPDATE_SUBSCRIPTION,DETERMINE_ACTION,LOG_CHECK,UPDATE_TIMESTAMP,STORE_RESPONSE processing
    class SUCCESS,PENDING,FAILED,RETRY_NEEDED decision
    class SCHEDULE_NEXT,TRIGGER_RETRY,COMPLETE endNode
```

**ğŸ” ExplicaÃ§Ã£o do Fluxo Checker:**

O **Checker** Ã© o componente responsÃ¡vel por **monitorar o status de processamento** das inscriÃ§Ãµes nas instituiÃ§Ãµes:

1. **Monitoramento de Status**:
   - Executa periodicamente para verificar inscriÃ§Ãµes pendentes
   - Identifica inscriÃ§Ãµes que precisam de verificaÃ§Ã£o de status
   - Filtra apenas aquelas que atingiram o tempo de verificaÃ§Ã£o programado

2. **VerificaÃ§Ã£o via API**:
   - Chama APIs de status das instituiÃ§Ãµes para consultar andamento
   - Faz parsing das respostas que podem ter formatos diferentes por instituiÃ§Ã£o
   - Extrai informaÃ§Ãµes relevantes sobre o status atual da inscriÃ§Ã£o

3. **Processamento de Status**:
   - Compara status atual com status anterior armazenado
   - Atualiza informaÃ§Ãµes da inscriÃ§Ã£o no banco de dados
   - Determina prÃ³xima aÃ§Ã£o baseada no novo status

4. **Logging de Eventos**:
   - Registra cada verificaÃ§Ã£o realizada
   - Atualiza timestamp da Ãºltima verificaÃ§Ã£o
   - Armazena resposta completa da API para auditoria

5. **DecisÃµes de Fluxo**:
   - **Sucesso**: InscriÃ§Ã£o foi processada com sucesso pela instituiÃ§Ã£o
   - **Pendente**: Ainda em processamento, agenda prÃ³xima verificaÃ§Ã£o
   - **Falha**: Processamento falhou na instituiÃ§Ã£o, marca como erro
   - **Retry**: Problema temporÃ¡rio, agenda nova tentativa de envio

**ğŸ¯ Objetivo do Checker:**
Garantir que todas as inscriÃ§Ãµes enviadas sejam devidamente processadas pelas instituiÃ§Ãµes, fornecendo visibilidade completa do pipeline de integraÃ§Ã£o e permitindo intervenÃ§Ãµes quando necessÃ¡rio.

## Outras docs

- PÃ¡gina do produto: https://www.notion.so/quero
- [Anubis Docs](https://github.com/quero-edu/anubis/tree/main/docs)

